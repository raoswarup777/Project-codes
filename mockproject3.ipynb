{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mostcommon.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Serena', 'PROPN'],\n",
       " ['Andrew', 'PROPN'],\n",
       " ['Bobbie', 'PROPN'],\n",
       " ['Cason', 'PROPN'],\n",
       " ['David', 'PROPN'],\n",
       " ['Farzana', 'PROPN'],\n",
       " ['Frank', 'PROPN'],\n",
       " ['Hannah', 'PROPN'],\n",
       " ['Ida', 'PROPN'],\n",
       " ['Irene', 'PROPN'],\n",
       " ['Jim', 'PROPN'],\n",
       " ['Jose', 'PROPN'],\n",
       " ['Keith', 'PROPN'],\n",
       " ['Laura', 'PROPN'],\n",
       " ['Lucy', 'PROPN'],\n",
       " ['Meredith', 'PROPN'],\n",
       " ['Nick', 'PROPN'],\n",
       " ['Ada', 'PROPN'],\n",
       " ['Yeeling', 'PROPN'],\n",
       " ['Yan', 'PROPN'],\n",
       " ['the', 'DET'],\n",
       " ['of', 'ADP'],\n",
       " ['to', 'ADP'],\n",
       " ['and', 'CCONJ'],\n",
       " ['a', 'DET'],\n",
       " ['in', 'NOUN'],\n",
       " ['is', 'AUX'],\n",
       " ['it', 'PRON'],\n",
       " ['you', 'PRON'],\n",
       " ['that', 'SCONJ'],\n",
       " ['he', 'PRON'],\n",
       " ['was', 'AUX'],\n",
       " ['for', 'ADP'],\n",
       " ['on', 'ADV'],\n",
       " ['are', 'AUX'],\n",
       " ['with', 'ADP'],\n",
       " ['as', 'ADP'],\n",
       " ['I', 'PRON'],\n",
       " ['his', 'PRON'],\n",
       " ['they', 'PRON'],\n",
       " ['be', 'VERB'],\n",
       " ['at', 'ADP'],\n",
       " ['one', 'NUM'],\n",
       " ['have', 'VERB'],\n",
       " ['this', 'DET'],\n",
       " ['from', 'ADP'],\n",
       " ['or', 'CCONJ'],\n",
       " ['had', 'VERB'],\n",
       " ['by', 'ADP'],\n",
       " ['hot', 'ADJ'],\n",
       " ['but', 'CCONJ'],\n",
       " ['some', 'DET'],\n",
       " ['what', 'PRON'],\n",
       " ['there', 'ADV'],\n",
       " ['we', 'PRON'],\n",
       " ['can', 'AUX'],\n",
       " ['out', 'ADV'],\n",
       " ['other', 'ADJ'],\n",
       " ['were', 'AUX'],\n",
       " ['all', 'DET'],\n",
       " ['your', 'PRON'],\n",
       " ['when', 'ADV'],\n",
       " ['up', 'ADP'],\n",
       " ['use', 'VERB'],\n",
       " ['word', 'NOUN'],\n",
       " ['how', 'ADV'],\n",
       " ['said', 'VERB'],\n",
       " ['an', 'DET'],\n",
       " ['each', 'DET'],\n",
       " ['she', 'PRON'],\n",
       " ['which', 'DET'],\n",
       " ['do', 'VERB'],\n",
       " ['their', 'PRON'],\n",
       " ['time', 'NOUN'],\n",
       " ['if', 'SCONJ'],\n",
       " ['will', 'AUX'],\n",
       " ['way', 'VERB'],\n",
       " ['about', 'ADV'],\n",
       " ['many', 'ADJ'],\n",
       " ['then', 'ADV'],\n",
       " ['them', 'PRON'],\n",
       " ['would', 'AUX'],\n",
       " ['write', 'VERB'],\n",
       " ['like', 'ADP'],\n",
       " ['so', 'ADV'],\n",
       " ['these', 'DET'],\n",
       " ['her', 'PRON'],\n",
       " ['long', 'ADJ'],\n",
       " ['make', 'NOUN'],\n",
       " ['thing', 'NOUN'],\n",
       " ['see', 'VERB'],\n",
       " ['him', 'PRON'],\n",
       " ['two', 'NUM'],\n",
       " ['has', 'AUX'],\n",
       " ['look', 'VERB'],\n",
       " ['more', 'ADJ'],\n",
       " ['day', 'NOUN'],\n",
       " ['could', 'AUX'],\n",
       " ['go', 'VERB'],\n",
       " ['come', 'VERB'],\n",
       " ['did', 'VERB'],\n",
       " ['my', 'PRON'],\n",
       " ['sound', 'NOUN'],\n",
       " ['no', 'DET'],\n",
       " ['most', 'ADJ'],\n",
       " ['number', 'NOUN'],\n",
       " ['who', 'PRON'],\n",
       " ['over', 'ADP'],\n",
       " ['know', 'VERB'],\n",
       " ['water', 'NOUN'],\n",
       " ['than', 'SCONJ'],\n",
       " ['call', 'VERB'],\n",
       " ['first', 'ADJ'],\n",
       " ['people', 'NOUN'],\n",
       " ['may', 'AUX'],\n",
       " ['down', 'ADV'],\n",
       " ['side', 'NOUN'],\n",
       " ['been', 'AUX'],\n",
       " ['now', 'ADV'],\n",
       " ['find', 'VERB'],\n",
       " ['any', 'DET'],\n",
       " ['new', 'ADJ'],\n",
       " ['work', 'NOUN'],\n",
       " ['part', 'NOUN'],\n",
       " ['take', 'VERB'],\n",
       " ['get', 'VERB'],\n",
       " ['place', 'NOUN'],\n",
       " ['made', 'VERB'],\n",
       " ['live', 'ADJ'],\n",
       " ['where', 'ADV'],\n",
       " ['after', 'ADP'],\n",
       " ['back', 'ADV'],\n",
       " ['little', 'ADJ'],\n",
       " ['only', 'ADJ'],\n",
       " ['round', 'ADJ'],\n",
       " ['man', 'NOUN'],\n",
       " ['year', 'NOUN'],\n",
       " ['came', 'VERB'],\n",
       " ['show', 'VERB'],\n",
       " ['every', 'DET'],\n",
       " ['good', 'ADJ'],\n",
       " ['me', 'PRON'],\n",
       " ['give', 'VERB'],\n",
       " ['our', 'PRON'],\n",
       " ['under', 'ADP'],\n",
       " ['name', 'NOUN'],\n",
       " ['very', 'ADV'],\n",
       " ['through', 'ADP'],\n",
       " ['just', 'ADV'],\n",
       " ['form', 'VERB'],\n",
       " ['much', 'ADV'],\n",
       " ['great', 'ADJ'],\n",
       " ['think', 'NOUN'],\n",
       " ['say', 'VERB'],\n",
       " ['help', 'VERB'],\n",
       " ['low', 'ADJ'],\n",
       " ['line', 'NOUN'],\n",
       " ['before', 'ADP'],\n",
       " ['turn', 'NOUN'],\n",
       " ['cause', 'VERB'],\n",
       " ['same', 'ADJ'],\n",
       " ['mean', 'NOUN'],\n",
       " ['differ', 'VERB'],\n",
       " ['move', 'NOUN'],\n",
       " ['right', 'ADJ'],\n",
       " ['boy', 'INTJ'],\n",
       " ['old', 'ADJ'],\n",
       " ['too', 'ADV'],\n",
       " ['does', 'AUX'],\n",
       " ['tell', 'VERB'],\n",
       " ['sentence', 'NOUN'],\n",
       " ['set', 'NOUN'],\n",
       " ['three', 'NUM'],\n",
       " ['want', 'ADJ'],\n",
       " ['air', 'NOUN'],\n",
       " ['well', 'ADV'],\n",
       " ['also', 'ADV'],\n",
       " ['play', 'VERB'],\n",
       " ['small', 'ADJ'],\n",
       " ['end', 'NOUN'],\n",
       " ['put', 'VERB'],\n",
       " ['home', 'ADV'],\n",
       " ['read', 'VERB'],\n",
       " ['hand', 'NOUN'],\n",
       " ['port', 'NOUN'],\n",
       " ['large', 'ADJ'],\n",
       " ['spell', 'NOUN'],\n",
       " ['add', 'VERB'],\n",
       " ['even', 'ADV'],\n",
       " ['land', 'NOUN'],\n",
       " ['here', 'ADV'],\n",
       " ['must', 'AUX'],\n",
       " ['big', 'VERB'],\n",
       " ['high', 'ADJ'],\n",
       " ['such', 'ADJ'],\n",
       " ['follow', 'NOUN'],\n",
       " ['act', 'NOUN'],\n",
       " ['why', 'ADV'],\n",
       " ['ask', 'VERB'],\n",
       " ['men', 'NOUN'],\n",
       " ['change', 'VERB'],\n",
       " ['went', 'VERB'],\n",
       " ['light', 'ADJ'],\n",
       " ['kind', 'NOUN'],\n",
       " ['off', 'ADV'],\n",
       " ['need', 'VERB'],\n",
       " ['house', 'NOUN'],\n",
       " ['picture', 'NOUN'],\n",
       " ['try', 'VERB'],\n",
       " ['us', 'PRON'],\n",
       " ['again', 'ADV'],\n",
       " ['animal', 'NOUN'],\n",
       " ['point', 'NOUN'],\n",
       " ['mother', 'NOUN'],\n",
       " ['world', 'NOUN'],\n",
       " ['near', 'SCONJ'],\n",
       " ['build', 'VERB'],\n",
       " ['self', 'NOUN'],\n",
       " ['earth', 'NOUN'],\n",
       " ['father', 'NOUN'],\n",
       " ['head', 'NOUN'],\n",
       " ['stand', 'VERB'],\n",
       " ['own', 'ADJ'],\n",
       " ['page', 'NOUN'],\n",
       " ['should', 'AUX'],\n",
       " ['country', 'NOUN'],\n",
       " ['found', 'VERB'],\n",
       " ['answer', 'NOUN'],\n",
       " ['school', 'NOUN'],\n",
       " ['grow', 'NOUN'],\n",
       " ['study', 'NOUN'],\n",
       " ['still', 'ADV'],\n",
       " ['learn', 'VERB'],\n",
       " ['plant', 'NOUN'],\n",
       " ['cover', 'VERB'],\n",
       " ['food', 'NOUN'],\n",
       " ['sun', 'NOUN'],\n",
       " ['four', 'NUM'],\n",
       " ['thought', 'VERB'],\n",
       " ['let', 'VERB'],\n",
       " ['keep', 'VERB'],\n",
       " ['eye', 'NOUN'],\n",
       " ['never', 'ADV'],\n",
       " ['last', 'ADJ'],\n",
       " ['door', 'NOUN'],\n",
       " ['between', 'ADP'],\n",
       " ['city', 'NOUN'],\n",
       " ['tree', 'NOUN'],\n",
       " ['cross', 'NOUN'],\n",
       " ['since', 'SCONJ'],\n",
       " ['hard', 'ADJ'],\n",
       " ['start', 'NOUN'],\n",
       " ['might', 'AUX'],\n",
       " ['story', 'NOUN'],\n",
       " ['saw', 'VERB'],\n",
       " ['far', 'ADJ'],\n",
       " ['sea', 'NOUN'],\n",
       " ['draw', 'NOUN'],\n",
       " ['left', 'VERB'],\n",
       " ['late', 'ADJ'],\n",
       " ['run', 'NOUN'],\n",
       " ['do', 'AUX'],\n",
       " ['nâ€™t', 'PART'],\n",
       " ['while', 'SCONJ'],\n",
       " ['press', 'NOUN'],\n",
       " ['close', 'ADJ'],\n",
       " ['night', 'NOUN'],\n",
       " ['real', 'ADJ'],\n",
       " ['life', 'NOUN'],\n",
       " ['few', 'ADJ'],\n",
       " ['stop', 'VERB'],\n",
       " ['open', 'ADJ'],\n",
       " ['seem', 'VERB'],\n",
       " ['together', 'ADV'],\n",
       " ['next', 'ADP'],\n",
       " ['white', 'ADJ'],\n",
       " ['children', 'NOUN'],\n",
       " ['begin', 'VERB'],\n",
       " ['got', 'VERB'],\n",
       " ['walk', 'NOUN'],\n",
       " ['example', 'NOUN'],\n",
       " ['ease', 'NOUN'],\n",
       " ['paper', 'NOUN'],\n",
       " ['often', 'ADV'],\n",
       " ['always', 'ADV'],\n",
       " ['music', 'VERB'],\n",
       " ['those', 'DET'],\n",
       " ['both', 'DET'],\n",
       " ['mark', 'NOUN'],\n",
       " ['book', 'NOUN'],\n",
       " ['letter', 'NOUN'],\n",
       " ['until', 'ADP'],\n",
       " ['mile', 'NOUN'],\n",
       " ['river', 'NOUN'],\n",
       " ['car', 'NOUN'],\n",
       " ['feet', 'NOUN'],\n",
       " ['care', 'VERB'],\n",
       " ['second', 'ADJ'],\n",
       " ['group', 'NOUN'],\n",
       " ['carry', 'NOUN'],\n",
       " ['took', 'VERB'],\n",
       " ['rain', 'NOUN'],\n",
       " ['eat', 'NOUN'],\n",
       " ['room', 'NOUN'],\n",
       " ['friend', 'NOUN'],\n",
       " ['began', 'VERB'],\n",
       " ['idea', 'NOUN'],\n",
       " ['fish', 'NOUN'],\n",
       " ['mountain', 'NOUN'],\n",
       " ['north', 'NOUN'],\n",
       " ['once', 'ADV'],\n",
       " ['base', 'NOUN'],\n",
       " ['hear', 'VERB'],\n",
       " ['horse', 'NOUN'],\n",
       " ['cut', 'VERB'],\n",
       " ['sure', 'ADJ'],\n",
       " ['watch', 'NOUN'],\n",
       " ['color', 'NOUN'],\n",
       " ['face', 'VERB'],\n",
       " ['wood', 'NOUN'],\n",
       " ['main', 'ADJ'],\n",
       " ['enough', 'ADJ'],\n",
       " ['plain', 'ADJ'],\n",
       " ['girl', 'NOUN'],\n",
       " ['usual', 'ADJ'],\n",
       " ['young', 'ADJ'],\n",
       " ['ready', 'ADJ'],\n",
       " ['above', 'ADP'],\n",
       " ['ever', 'ADV'],\n",
       " ['red', 'ADJ'],\n",
       " ['list', 'NOUN'],\n",
       " ['though', 'ADV'],\n",
       " ['feel', 'VERB'],\n",
       " ['talk', 'NOUN'],\n",
       " ['bird', 'NOUN'],\n",
       " ['soon', 'ADV'],\n",
       " ['body', 'NOUN'],\n",
       " ['dog', 'NOUN'],\n",
       " ['family', 'NOUN'],\n",
       " ['direct', 'ADJ'],\n",
       " ['pose', 'NOUN'],\n",
       " ['leave', 'VERB'],\n",
       " ['song', 'NOUN'],\n",
       " ['measure', 'NOUN'],\n",
       " ['state', 'NOUN'],\n",
       " ['product', 'NOUN'],\n",
       " ['black', 'ADJ'],\n",
       " ['short', 'ADJ'],\n",
       " ['numeral', 'ADJ'],\n",
       " ['class', 'NOUN'],\n",
       " ['wind', 'NOUN'],\n",
       " ['question', 'NOUN'],\n",
       " ['happen', 'VERB'],\n",
       " ['complete', 'ADJ'],\n",
       " ['ship', 'NOUN'],\n",
       " ['area', 'NOUN'],\n",
       " ['half', 'ADJ'],\n",
       " ['rock', 'NOUN'],\n",
       " ['order', 'NOUN'],\n",
       " ['fire', 'NOUN'],\n",
       " ['south', 'ADJ'],\n",
       " ['problem', 'NOUN'],\n",
       " ['piece', 'NOUN'],\n",
       " ['told', 'VERB'],\n",
       " ['knew', 'VERB'],\n",
       " ['pass', 'VERB'],\n",
       " ['farm', 'NOUN'],\n",
       " ['top', 'ADJ'],\n",
       " ['whole', 'ADJ'],\n",
       " ['king', 'NOUN'],\n",
       " ['size', 'NOUN'],\n",
       " ['heard', 'VERB'],\n",
       " ['best', 'ADJ'],\n",
       " ['hour', 'NOUN'],\n",
       " ['better', 'ADV'],\n",
       " ['true', 'ADJ'],\n",
       " ['during', 'ADP'],\n",
       " ['hundred', 'NUM'],\n",
       " ['am', 'VERB'],\n",
       " ['remember', 'VERB'],\n",
       " ['step', 'NOUN'],\n",
       " ['early', 'ADV'],\n",
       " ['hold', 'VERB'],\n",
       " ['west', 'ADJ'],\n",
       " ['ground', 'NOUN'],\n",
       " ['interest', 'NOUN'],\n",
       " ['reach', 'VERB'],\n",
       " ['fast', 'ADV'],\n",
       " ['five', 'NUM'],\n",
       " ['sing', 'VERB'],\n",
       " ['listen', 'NOUN'],\n",
       " ['six', 'NUM'],\n",
       " ['table', 'NOUN'],\n",
       " ['travel', 'NOUN'],\n",
       " ['less', 'ADJ'],\n",
       " ['morning', 'NOUN'],\n",
       " ['ten', 'NUM'],\n",
       " ['simple', 'ADJ'],\n",
       " ['several', 'ADJ'],\n",
       " ['vowel', 'NOUN'],\n",
       " ['toward', 'ADP'],\n",
       " ['war', 'NOUN'],\n",
       " ['lay', 'VERB'],\n",
       " ['against', 'ADP'],\n",
       " ['pattern', 'NOUN'],\n",
       " ['slow', 'ADJ'],\n",
       " ['center', 'NOUN'],\n",
       " ['love', 'NOUN'],\n",
       " ['person', 'NOUN'],\n",
       " ['money', 'NOUN'],\n",
       " ['serve', 'VERB'],\n",
       " ['appear', 'VERB'],\n",
       " ['road', 'NOUN'],\n",
       " ['map', 'NOUN'],\n",
       " ['science', 'NOUN'],\n",
       " ['rule', 'NOUN'],\n",
       " ['govern', 'NOUN'],\n",
       " ['pull', 'VERB'],\n",
       " ['cold', 'ADJ'],\n",
       " ['notice', 'NOUN'],\n",
       " ['voice', 'NOUN'],\n",
       " ['fall', 'VERB'],\n",
       " ['power', 'NOUN'],\n",
       " ['town', 'NOUN'],\n",
       " ['fine', 'ADJ'],\n",
       " ['certain', 'ADJ'],\n",
       " ['fly', 'NOUN'],\n",
       " ['unit', 'NOUN'],\n",
       " ['lead', 'VERB'],\n",
       " ['cry', 'VERB'],\n",
       " ['dark', 'ADJ'],\n",
       " ['machine', 'NOUN'],\n",
       " ['note', 'NOUN'],\n",
       " ['wait', 'VERB'],\n",
       " ['plan', 'NOUN'],\n",
       " ['figure', 'NOUN'],\n",
       " ['star', 'NOUN'],\n",
       " ['box', 'NOUN'],\n",
       " ['noun', 'NOUN'],\n",
       " ['field', 'NOUN'],\n",
       " ['rest', 'NOUN'],\n",
       " ['correct', 'ADJ'],\n",
       " ['able', 'ADJ'],\n",
       " ['pound', 'NOUN'],\n",
       " ['done', 'VERB'],\n",
       " ['beauty', 'NOUN'],\n",
       " ['drive', 'NOUN'],\n",
       " ['stood', 'VERB'],\n",
       " ['contain', 'VERB'],\n",
       " ['front', 'NOUN'],\n",
       " ['teach', 'NOUN'],\n",
       " ['week', 'NOUN'],\n",
       " ['final', 'ADJ'],\n",
       " ['gave', 'VERB'],\n",
       " ['green', 'ADJ'],\n",
       " ['oh', 'INTJ'],\n",
       " ['quick', 'ADJ'],\n",
       " ['develop', 'VERB'],\n",
       " ['sleep', 'NOUN'],\n",
       " ['warm', 'ADJ'],\n",
       " ['free', 'ADJ'],\n",
       " ['minute', 'NOUN'],\n",
       " ['strong', 'ADJ'],\n",
       " ['special', 'ADJ'],\n",
       " ['mind', 'NOUN'],\n",
       " ['behind', 'ADP'],\n",
       " ['clear', 'ADJ'],\n",
       " ['tail', 'NOUN'],\n",
       " ['produce', 'VERB'],\n",
       " ['fact', 'NOUN'],\n",
       " ['street', 'NOUN'],\n",
       " ['inch', 'NOUN'],\n",
       " ['lot', 'NOUN'],\n",
       " ['nothing', 'PRON'],\n",
       " ['course', 'NOUN'],\n",
       " ['stay', 'VERB'],\n",
       " ['wheel', 'NOUN'],\n",
       " ['full', 'ADJ'],\n",
       " ['force', 'NOUN'],\n",
       " ['blue', 'ADJ'],\n",
       " ['object', 'NOUN'],\n",
       " ['decide', 'VERB'],\n",
       " ['surface', 'NOUN'],\n",
       " ['deep', 'ADJ'],\n",
       " ['moon', 'NOUN'],\n",
       " ['island', 'NOUN'],\n",
       " ['foot', 'NOUN'],\n",
       " ['yet', 'ADV'],\n",
       " ['busy', 'ADJ'],\n",
       " ['test', 'NOUN'],\n",
       " ['record', 'NOUN'],\n",
       " ['boat', 'NOUN'],\n",
       " ['common', 'ADJ'],\n",
       " ['gold', 'NOUN'],\n",
       " ['possible', 'ADJ'],\n",
       " ['plane', 'NOUN'],\n",
       " ['age', 'NOUN'],\n",
       " ['dry', 'ADJ'],\n",
       " ['wonder', 'NOUN'],\n",
       " ['laugh', 'NOUN'],\n",
       " ['thousand', 'NUM'],\n",
       " ['ago', 'ADV'],\n",
       " ['ran', 'VERB'],\n",
       " ['check', 'NOUN'],\n",
       " ['game', 'NOUN'],\n",
       " ['shape', 'NOUN'],\n",
       " ['yes', 'INTJ'],\n",
       " ['cool', 'INTJ'],\n",
       " ['miss', 'NOUN'],\n",
       " ['brought', 'VERB'],\n",
       " ['heat', 'NOUN'],\n",
       " ['snow', 'NOUN'],\n",
       " ['bed', 'NOUN'],\n",
       " ['bring', 'VERB'],\n",
       " ['sit', 'VERB'],\n",
       " ['perhaps', 'ADV'],\n",
       " ['fill', 'VERB'],\n",
       " ['east', 'NOUN'],\n",
       " ['weight', 'NOUN'],\n",
       " ['language', 'NOUN'],\n",
       " ['among', 'ADP']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "data = 'Serena Andrew Bobbie Cason David Farzana Frank Hannah Ida Irene Jim Jose Keith Laura Lucy Meredith Nick Ada Yeeling Yan the of to and a in is it you that he was for on are with as I his they be at one have this from or had by hot but some what there we can out other were all your when up use word how said an each she which do their time if will way about many then them would write like so these her long make thing see him two has look more day could go come did my sound no most number who over know water than call first people may down side been now find any new work part take get place made live where after back little only round man year came show every good me give our under name very through just form much great think say help low line before turn cause same mean differ move right boy old too does tell sentence set three want air well also play small end put home read hand port large spell add even land here must big high such follow act why ask men change went light kind off need house picture try us again animal point mother world near build self earth father head stand own page should country found answer school grow study still learn plant cover food sun four thought let keep eye never last door between city tree cross since hard start might story saw far sea draw left late run donâ€™t while press close night real life few stop open seem together next white children begin got walk example ease paper often always music those both mark book letter until mile river car feet care second group carry took rain eat room friend began idea fish mountain north once base hear horse cut sure watch color face wood main enough plain girl usual young ready above ever red list though feel talk bird soon body dog family direct pose leave song measure state product black short numeral class wind question happen complete ship area half rock order fire south problem piece told knew pass farm top whole king size heard best hour better true during hundred am remember step early hold west ground interest reach fast five sing listen six table travel less morning ten simple several vowel toward war lay against pattern slow center love person money serve appear road map science rule govern pull cold notice voice fall power town fine certain fly unit lead cry dark machine note wait plan figure star box noun field rest correct able pound done beauty drive stood contain front teach week final gave green oh quick develop sleep warm free minute strong special mind behind clear tail produce fact street inch lot nothing course stay wheel full force blue object decide surface deep moon island foot yet busy test record boat common gold possible plane age dry wonder laugh thousand ago ran check game shape yes cool miss brought heat snow bed bring sit perhaps fill east weight language among '\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(data)\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    tokens.append([token.text+\" \"+token.pos_])\n",
    "content_list2=[]\n",
    "for i in range(0,len(tokens)):\n",
    "    content_list2.append(tokens[i][0].split(\" \"))\n",
    "content_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list2=[['Serena', 'PROPN'],\n",
    " ['Andrew', 'PROPN'],\n",
    " ['Bobbie', 'PROPN'],\n",
    " ['Cason', 'PROPN'],\n",
    " ['David', 'PROPN'],\n",
    " ['Farzana', 'PROPN'],\n",
    " ['Frank', 'PROPN'],\n",
    " ['Hannah', 'PROPN'],\n",
    " ['Ida', 'PROPN'],\n",
    " ['Irene', 'PROPN'],\n",
    " ['Jim', 'PROPN'],\n",
    " ['Jose', 'PROPN'],\n",
    " ['Keith', 'PROPN'],\n",
    " ['Laura', 'PROPN'],\n",
    " ['Lucy', 'PROPN'],\n",
    " ['Red', 'PROPN'],                    \n",
    " ['Meredith', 'PROPN'],\n",
    " ['Nick', 'PROPN'],\n",
    " ['Ada', 'PROPN'],\n",
    " ['Yeeling', 'PROPN'],\n",
    " ['Yan', 'PROPN'],\n",
    " ['the', 'DET'],\n",
    " ['of', 'ADP'],\n",
    " ['to', 'ADP'],\n",
    " ['and', 'CCONJ'],\n",
    " ['a', 'DET'],\n",
    " ['in', 'NOUN'],\n",
    " ['is', 'AUX'],\n",
    " ['it', 'PRON'],\n",
    " ['you', 'PRON'],\n",
    " ['that', 'SCONJ'],\n",
    " ['he', 'PRON'],\n",
    " ['was', 'AUX'],\n",
    " ['for', 'ADP'],\n",
    " ['on', 'ADV'],\n",
    " ['are', 'AUX'],\n",
    " ['with', 'ADP'],\n",
    " ['as', 'ADP'],\n",
    " ['I', 'PRON'],\n",
    " ['his', 'PRON'],\n",
    " ['they', 'PRON'],\n",
    " ['be', 'VERB'],\n",
    " ['at', 'ADP'],\n",
    " ['one', 'NUM'],\n",
    " ['have', 'VERB'],\n",
    " ['this', 'DET'],\n",
    " ['from', 'ADP'],\n",
    " ['or', 'CCONJ'],\n",
    " ['had', 'VERB'],\n",
    " ['by', 'ADP'],\n",
    " ['hot', 'ADJ'],\n",
    " ['but', 'CCONJ'],\n",
    " ['some', 'DET'],\n",
    " ['what', 'PRON'],\n",
    " ['there', 'ADV'],\n",
    " ['we', 'PRON'],\n",
    " ['can', 'AUX'],\n",
    " ['out', 'ADV'],\n",
    " ['other', 'ADJ'],\n",
    " ['were', 'AUX'],\n",
    " ['all', 'DET'],\n",
    " ['your', 'PRON'],\n",
    " ['when', 'ADV'],\n",
    " ['up', 'ADP'],\n",
    " ['use', 'VERB'],\n",
    " ['word', 'NOUN'],\n",
    " ['how', 'ADV'],\n",
    " ['said', 'VERB'],\n",
    " ['an', 'DET'],\n",
    " ['each', 'DET'],\n",
    " ['she', 'PRON'],\n",
    " ['which', 'DET'],\n",
    " ['do', 'VERB'],\n",
    " ['their', 'PRON'],\n",
    " ['time', 'NOUN'],\n",
    " ['if', 'SCONJ'],\n",
    " ['will', 'AUX'],\n",
    " ['way', 'VERB'],\n",
    " ['about', 'ADV'],\n",
    " ['many', 'ADJ'],\n",
    " ['then', 'ADV'],\n",
    " ['them', 'PRON'],\n",
    " ['would', 'AUX'],\n",
    " ['write', 'VERB'],\n",
    " ['like', 'ADP'],\n",
    " ['so', 'ADV'],\n",
    " ['these', 'DET'],\n",
    " ['her', 'PRON'],\n",
    " ['long', 'ADJ'],\n",
    " ['make', 'NOUN'],\n",
    " ['thing', 'NOUN'],\n",
    " ['see', 'VERB'],\n",
    " ['him', 'PRON'],\n",
    " ['two', 'NUM'],\n",
    " ['has', 'AUX'],\n",
    " ['look', 'VERB'],\n",
    " ['more', 'ADJ'],\n",
    " ['day', 'NOUN'],\n",
    " ['could', 'AUX'],\n",
    " ['go', 'VERB'],\n",
    " ['come', 'VERB'],\n",
    " ['did', 'VERB'],\n",
    " ['my', 'PRON'],\n",
    " ['sound', 'NOUN'],\n",
    " ['no', 'DET'],\n",
    " ['most', 'ADJ'],\n",
    " ['number', 'NOUN'],\n",
    " ['who', 'PRON'],\n",
    " ['over', 'ADP'],\n",
    " ['know', 'VERB'],\n",
    " ['water', 'NOUN'],\n",
    " ['than', 'SCONJ'],\n",
    " ['call', 'VERB'],\n",
    " ['first', 'ADJ'],\n",
    " ['people', 'NOUN'],\n",
    " ['may', 'AUX'],\n",
    " ['down', 'ADV'],\n",
    " ['side', 'NOUN'],\n",
    " ['been', 'AUX'],\n",
    " ['now', 'ADV'],\n",
    " ['find', 'VERB'],\n",
    " ['any', 'DET'],\n",
    " ['new', 'ADJ'],\n",
    " ['work', 'NOUN'],\n",
    " ['part', 'NOUN'],\n",
    " ['take', 'VERB'],\n",
    " ['get', 'VERB'],\n",
    " ['place', 'NOUN'],\n",
    " ['made', 'VERB'],\n",
    " ['live', 'ADJ'],\n",
    " ['where', 'ADV'],\n",
    " ['after', 'ADP'],\n",
    " ['back', 'ADV'],\n",
    " ['little', 'ADJ'],\n",
    " ['only', 'ADJ'],\n",
    " ['round', 'ADJ'],\n",
    " ['man', 'NOUN'],\n",
    " ['year', 'NOUN'],\n",
    " ['came', 'VERB'],\n",
    " ['show', 'VERB'],\n",
    " ['every', 'DET'],\n",
    " ['good', 'ADJ'],\n",
    " ['me', 'PRON'],\n",
    " ['give', 'VERB'],\n",
    " ['our', 'PRON'],\n",
    " ['under', 'ADP'],\n",
    " ['name', 'NOUN'],\n",
    " ['very', 'ADV'],\n",
    " ['through', 'ADP'],\n",
    " ['just', 'ADV'],\n",
    " ['form', 'VERB'],\n",
    " ['much', 'ADV'],\n",
    " ['great', 'ADJ'],\n",
    " ['think', 'NOUN'],\n",
    " ['say', 'VERB'],\n",
    " ['help', 'VERB'],\n",
    " ['low', 'ADJ'],\n",
    " ['line', 'NOUN'],\n",
    " ['before', 'ADP'],\n",
    " ['turn', 'NOUN'],\n",
    " ['cause', 'VERB'],\n",
    " ['same', 'ADJ'],\n",
    " ['mean', 'NOUN'],\n",
    " ['differ', 'VERB'],\n",
    " ['move', 'NOUN'],\n",
    " ['right', 'ADJ'],\n",
    " ['boy', 'INTJ'],\n",
    " ['old', 'ADJ'],\n",
    " ['too', 'ADV'],\n",
    " ['does', 'AUX'],\n",
    " ['tell', 'VERB'],\n",
    " ['sentence', 'NOUN'],\n",
    " ['set', 'NOUN'],\n",
    " ['three', 'NUM'],\n",
    " ['want', 'ADJ'],\n",
    " ['air', 'NOUN'],\n",
    " ['well', 'ADV'],\n",
    " ['also', 'ADV'],\n",
    " ['play', 'VERB'],\n",
    " ['small', 'ADJ'],\n",
    " ['end', 'NOUN'],\n",
    " ['put', 'VERB'],\n",
    " ['home', 'ADV'],\n",
    " ['read', 'VERB'],\n",
    " ['hand', 'NOUN'],\n",
    " ['port', 'NOUN'],\n",
    " ['large', 'ADJ'],\n",
    " ['spell', 'NOUN'],\n",
    " ['add', 'VERB'],\n",
    " ['even', 'ADV'],\n",
    " ['land', 'NOUN'],\n",
    " ['here', 'ADV'],\n",
    " ['must', 'AUX'],\n",
    " ['big', 'ADJ'],\n",
    " ['high', 'ADJ'],\n",
    " ['such', 'ADJ'],\n",
    " ['follow', 'NOUN'],\n",
    " ['act', 'NOUN'],\n",
    " ['why', 'ADV'],\n",
    " ['ask', 'VERB'],\n",
    " ['men', 'NOUN'],\n",
    " ['change', 'VERB'],\n",
    " ['went', 'VERB'],\n",
    " ['light', 'ADJ'],\n",
    " ['kind', 'NOUN'],\n",
    " ['off', 'ADV'],\n",
    " ['need', 'VERB'],\n",
    " ['house', 'NOUN'],\n",
    " ['picture', 'NOUN'],\n",
    " ['try', 'VERB'],\n",
    " ['us', 'PRON'],\n",
    " ['again', 'ADV'],\n",
    " ['animal', 'NOUN'],\n",
    " ['point', 'NOUN'],\n",
    " ['mother', 'NOUN'],\n",
    " ['world', 'NOUN'],\n",
    " ['near', 'SCONJ'],\n",
    " ['build', 'VERB'],\n",
    " ['self', 'NOUN'],\n",
    " ['earth', 'NOUN'],\n",
    " ['father', 'NOUN'],\n",
    " ['head', 'NOUN'],\n",
    " ['stand', 'VERB'],\n",
    " ['own', 'ADJ'],\n",
    " ['page', 'NOUN'],\n",
    " ['should', 'AUX'],\n",
    " ['country', 'NOUN'],\n",
    " ['found', 'VERB'],\n",
    " ['answer', 'NOUN'],\n",
    " ['school', 'NOUN'],\n",
    " ['grow', 'NOUN'],\n",
    " ['study', 'NOUN'],\n",
    " ['still', 'ADV'],\n",
    " ['learn', 'VERB'],\n",
    " ['plant', 'NOUN'],\n",
    " ['cover', 'VERB'],\n",
    " ['food', 'NOUN'],\n",
    " ['sun', 'NOUN'],\n",
    " ['four', 'NUM'],\n",
    " ['thought', 'VERB'],\n",
    " ['let', 'VERB'],\n",
    " ['keep', 'VERB'],\n",
    " ['eye', 'NOUN'],\n",
    " ['never', 'ADV'],\n",
    " ['last', 'ADJ'],\n",
    " ['door', 'NOUN'],\n",
    " ['between', 'ADP'],\n",
    " ['city', 'NOUN'],\n",
    " ['tree', 'NOUN'],\n",
    " ['cross', 'NOUN'],\n",
    " ['since', 'SCONJ'],\n",
    " ['hard', 'ADJ'],\n",
    " ['start', 'NOUN'],\n",
    " ['might', 'AUX'],\n",
    " ['story', 'NOUN'],\n",
    " ['saw', 'VERB'],\n",
    " ['far', 'ADJ'],\n",
    " ['sea', 'NOUN'],\n",
    " ['draw', 'NOUN'],\n",
    " ['left', 'VERB'],\n",
    " ['late', 'ADJ'],\n",
    " ['run', 'NOUN'],\n",
    " ['do', 'AUX'],\n",
    " ['nâ€™t', 'PART'],\n",
    " ['while', 'SCONJ'],\n",
    " ['press', 'NOUN'],\n",
    " ['close', 'ADJ'],\n",
    " ['night', 'NOUN'],\n",
    " ['real', 'ADJ'],\n",
    " ['life', 'NOUN'],\n",
    " ['few', 'ADJ'],\n",
    " ['stop', 'VERB'],\n",
    " ['open', 'ADJ'],\n",
    " ['seem', 'VERB'],\n",
    " ['together', 'ADV'],\n",
    " ['next', 'ADP'],\n",
    " ['white', 'ADJ'],\n",
    " ['children', 'NOUN'],\n",
    " ['begin', 'VERB'],\n",
    " ['got', 'VERB'],\n",
    " ['walk', 'NOUN'],\n",
    " ['example', 'NOUN'],\n",
    " ['ease', 'NOUN'],\n",
    " ['paper', 'NOUN'],\n",
    " ['often', 'ADV'],\n",
    " ['always', 'ADV'],\n",
    " ['music', 'VERB'],\n",
    " ['those', 'DET'],\n",
    " ['both', 'DET'],\n",
    " ['mark', 'NOUN'],\n",
    " ['book', 'NOUN'],\n",
    " ['letter', 'NOUN'],\n",
    " ['until', 'ADP'],\n",
    " ['mile', 'NOUN'],\n",
    " ['river', 'NOUN'],\n",
    " ['car', 'NOUN'],\n",
    " ['feet', 'NOUN'],\n",
    " ['care', 'VERB'],\n",
    " ['second', 'ADJ'],\n",
    " ['group', 'NOUN'],\n",
    " ['carry', 'NOUN'],\n",
    " ['took', 'VERB'],\n",
    " ['rain', 'NOUN'],\n",
    " ['eat', 'NOUN'],\n",
    " ['room', 'NOUN'],\n",
    " ['friend', 'NOUN'],\n",
    " ['began', 'VERB'],\n",
    " ['idea', 'NOUN'],\n",
    " ['fish', 'NOUN'],\n",
    " ['mountain', 'NOUN'],\n",
    " ['north', 'NOUN'],\n",
    " ['once', 'ADV'],\n",
    " ['base', 'NOUN'],\n",
    " ['hear', 'VERB'],\n",
    " ['horse', 'NOUN'],\n",
    " ['cut', 'VERB'],\n",
    " ['sure', 'ADJ'],\n",
    " ['watch', 'NOUN'],\n",
    " ['color', 'NOUN'],\n",
    " ['face', 'VERB'],\n",
    " ['wood', 'NOUN'],\n",
    " ['main', 'ADJ'],\n",
    " ['enough', 'ADJ'],\n",
    " ['plain', 'ADJ'],\n",
    " ['girl', 'NOUN'],\n",
    " ['usual', 'ADJ'],\n",
    " ['young', 'ADJ'],\n",
    " ['ready', 'ADJ'],\n",
    " ['above', 'ADP'],\n",
    " ['ever', 'ADV'],\n",
    " ['list', 'NOUN'],\n",
    " ['though', 'ADV'],\n",
    " ['feel', 'VERB'],\n",
    " ['talk', 'NOUN'],\n",
    " ['bird', 'NOUN'],\n",
    " ['soon', 'ADV'],\n",
    " ['body', 'NOUN'],\n",
    " ['dog', 'NOUN'],\n",
    " ['family', 'NOUN'],\n",
    " ['direct', 'ADJ'],\n",
    " ['pose', 'NOUN'],\n",
    " ['leave', 'VERB'],\n",
    " ['song', 'NOUN'],\n",
    " ['measure', 'NOUN'],\n",
    " ['state', 'NOUN'],\n",
    " ['product', 'NOUN'],\n",
    " ['black', 'ADJ'],\n",
    " ['short', 'ADJ'],\n",
    " ['numeral', 'ADJ'],\n",
    " ['class', 'NOUN'],\n",
    " ['wind', 'NOUN'],\n",
    " ['question', 'NOUN'],\n",
    " ['happen', 'VERB'],\n",
    " ['complete', 'ADJ'],\n",
    " ['ship', 'NOUN'],\n",
    " ['area', 'NOUN'],\n",
    " ['half', 'ADJ'],\n",
    " ['rock', 'NOUN'],\n",
    " ['order', 'NOUN'],\n",
    " ['fire', 'NOUN'],\n",
    " ['south', 'ADJ'],\n",
    " ['problem', 'NOUN'],\n",
    " ['piece', 'NOUN'],\n",
    " ['told', 'VERB'],\n",
    " ['knew', 'VERB'],\n",
    " ['pass', 'VERB'],\n",
    " ['farm', 'NOUN'],\n",
    " ['top', 'ADJ'],\n",
    " ['whole', 'ADJ'],\n",
    " ['king', 'NOUN'],\n",
    " ['size', 'NOUN'],\n",
    " ['heard', 'VERB'],\n",
    " ['best', 'ADJ'],\n",
    " ['hour', 'NOUN'],\n",
    " ['better', 'ADV'],\n",
    " ['true', 'ADJ'],\n",
    " ['during', 'ADP'],\n",
    " ['hundred', 'NUM'],\n",
    " ['am', 'VERB'],\n",
    " ['remember', 'VERB'],\n",
    " ['step', 'NOUN'],\n",
    " ['early', 'ADV'],\n",
    " ['hold', 'VERB'],\n",
    " ['west', 'ADJ'],\n",
    " ['ground', 'NOUN'],\n",
    " ['interest', 'NOUN'],\n",
    " ['reach', 'VERB'],\n",
    " ['fast', 'ADV'],\n",
    " ['five', 'NUM'],\n",
    " ['sing', 'VERB'],\n",
    " ['listen', 'NOUN'],\n",
    " ['six', 'NUM'],\n",
    " ['table', 'NOUN'],\n",
    " ['travel', 'NOUN'],\n",
    " ['less', 'ADJ'],\n",
    " ['morning', 'NOUN'],\n",
    " ['ten', 'NUM'],\n",
    " ['simple', 'ADJ'],\n",
    " ['several', 'ADJ'],\n",
    " ['vowel', 'NOUN'],\n",
    " ['toward', 'ADP'],\n",
    " ['war', 'NOUN'],\n",
    " ['lay', 'VERB'],\n",
    " ['against', 'ADP'],\n",
    " ['pattern', 'NOUN'],\n",
    " ['slow', 'ADJ'],\n",
    " ['center', 'NOUN'],\n",
    " ['love', 'NOUN'],\n",
    " ['person', 'NOUN'],\n",
    " ['money', 'NOUN'],\n",
    " ['serve', 'VERB'],\n",
    " ['appear', 'VERB'],\n",
    " ['road', 'NOUN'],\n",
    " ['map', 'NOUN'],\n",
    " ['science', 'NOUN'],\n",
    " ['rule', 'NOUN'],\n",
    " ['govern', 'NOUN'],\n",
    " ['pull', 'VERB'],\n",
    " ['cold', 'ADJ'],\n",
    " ['notice', 'NOUN'],\n",
    " ['voice', 'NOUN'],\n",
    " ['fall', 'VERB'],\n",
    " ['power', 'NOUN'],\n",
    " ['town', 'NOUN'],\n",
    " ['fine', 'ADJ'],\n",
    " ['certain', 'ADJ'],\n",
    " ['fly', 'NOUN'],\n",
    " ['unit', 'NOUN'],\n",
    " ['lead', 'VERB'],\n",
    " ['cry', 'VERB'],\n",
    " ['dark', 'ADJ'],\n",
    " ['machine', 'NOUN'],\n",
    " ['note', 'NOUN'],\n",
    " ['wait', 'VERB'],\n",
    " ['plan', 'NOUN'],\n",
    " ['figure', 'NOUN'],\n",
    " ['star', 'NOUN'],\n",
    " ['box', 'NOUN'],\n",
    " ['noun', 'NOUN'],\n",
    " ['field', 'NOUN'],\n",
    " ['rest', 'NOUN'],\n",
    " ['correct', 'ADJ'],\n",
    " ['able', 'ADJ'],\n",
    " ['pound', 'NOUN'],\n",
    " ['done', 'VERB'],\n",
    " ['beauty', 'NOUN'],\n",
    " ['drive', 'NOUN'],\n",
    " ['stood', 'VERB'],\n",
    " ['contain', 'VERB'],\n",
    " ['front', 'NOUN'],\n",
    " ['teach', 'NOUN'],\n",
    " ['week', 'NOUN'],\n",
    " ['final', 'ADJ'],\n",
    " ['gave', 'VERB'],\n",
    " ['green', 'ADJ'],\n",
    " ['oh', 'INTJ'],\n",
    " ['quick', 'ADJ'],\n",
    " ['develop', 'VERB'],\n",
    " ['sleep', 'NOUN'],\n",
    " ['warm', 'ADJ'],\n",
    " ['free', 'ADJ'],\n",
    " ['minute', 'NOUN'],\n",
    " ['strong', 'ADJ'],\n",
    " ['special', 'ADJ'],\n",
    " ['mind', 'NOUN'],\n",
    " ['behind', 'ADP'],\n",
    " ['clear', 'ADJ'],\n",
    " ['tail', 'NOUN'],\n",
    " ['produce', 'VERB'],\n",
    " ['fact', 'NOUN'],\n",
    " ['street', 'NOUN'],\n",
    " ['inch', 'NOUN'],\n",
    " ['lot', 'NOUN'],\n",
    " ['nothing', 'PRON'],\n",
    " ['course', 'NOUN'],\n",
    " ['stay', 'VERB'],\n",
    " ['wheel', 'NOUN'],\n",
    " ['full', 'ADJ'],\n",
    " ['force', 'NOUN'],\n",
    " ['blue', 'ADJ'],\n",
    " ['object', 'NOUN'],\n",
    " ['decide', 'VERB'],\n",
    " ['surface', 'NOUN'],\n",
    " ['deep', 'ADJ'],\n",
    " ['moon', 'NOUN'],\n",
    " ['island', 'NOUN'],\n",
    " ['foot', 'NOUN'],\n",
    " ['yet', 'ADV'],\n",
    " ['busy', 'ADJ'],\n",
    " ['test', 'NOUN'],\n",
    " ['record', 'NOUN'],\n",
    " ['boat', 'NOUN'],\n",
    " ['common', 'ADJ'],\n",
    " ['gold', 'NOUN'],\n",
    " ['possible', 'ADJ'],\n",
    " ['plane', 'NOUN'],\n",
    " ['age', 'NOUN'],\n",
    " ['dry', 'ADJ'],\n",
    " ['wonder', 'NOUN'],\n",
    " ['laugh', 'NOUN'],\n",
    " ['thousand', 'NUM'],\n",
    " ['ago', 'ADV'],\n",
    " ['ran', 'VERB'],\n",
    " ['check', 'NOUN'],\n",
    " ['game', 'NOUN'],\n",
    " ['shape', 'NOUN'],\n",
    " ['yes', 'INTJ'],\n",
    " ['cool', 'INTJ'],\n",
    " ['miss', 'NOUN'],\n",
    " ['brought', 'VERB'],\n",
    " ['heat', 'NOUN'],\n",
    " ['snow', 'NOUN'],\n",
    " ['bed', 'NOUN'],\n",
    " ['bring', 'VERB'],\n",
    " ['sit', 'VERB'],\n",
    " ['perhaps', 'ADV'],\n",
    " ['fill', 'VERB'],\n",
    " ['east', 'NOUN'],\n",
    " ['weight', 'NOUN'],\n",
    " ['language', 'NOUN'],\n",
    " ['among', 'ADP'],\n",
    " ['adults', 'NOUN'],\n",
    " ['wrote','VERB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors= '''amber\n",
    "ash\n",
    "asphalt\n",
    "auburn\n",
    "avocado\n",
    "aquamarine\n",
    "azure\n",
    "beige\n",
    "bisque\n",
    "black\n",
    "blue\n",
    "bone\n",
    "bordeaux\n",
    "brass\n",
    "bronze\n",
    "brown\n",
    "burgundy\n",
    "camel\n",
    "caramel\n",
    "canary\n",
    "celeste\n",
    "cerulean\n",
    "champagne\n",
    "charcoal\n",
    "chartreuse\n",
    "chestnut\n",
    "chocolate\n",
    "citron\n",
    "claret\n",
    "coal\n",
    "cobalt\n",
    "coffee\n",
    "coral\n",
    "corn\n",
    "cream\n",
    "crimson\n",
    "cyan\n",
    "denim\n",
    "desert\n",
    "ebony\n",
    "ecru\n",
    "emerald\n",
    "feldspar\n",
    "fuchsia\n",
    "gold\n",
    "gray\n",
    "green\n",
    "heather\n",
    "indigo\n",
    "ivory\n",
    "jet\n",
    "khaki\n",
    "lime\n",
    "magenta\n",
    "maroon\n",
    "mint\n",
    "navy\n",
    "olive\n",
    "orange\n",
    "pink\n",
    "plum\n",
    "purple\n",
    "red\n",
    "rust\n",
    "salmon\n",
    "sienna\n",
    "silver\n",
    "snow\n",
    "steel\n",
    "tan\n",
    "teal\n",
    "tomato\n",
    "violet\n",
    "white\n",
    "yellow'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list = colors.split('\\n')\n",
    "places = ['school', 'house','office','town','city','river','room',]\n",
    "time_day =['morning','evening','afternoon','night','yesterday','today','tomorrow','soon']\n",
    "distance_measures = ['mile','kilometers','meters']\n",
    "numbers=['ten','fifty','hundred','thousand']\n",
    "persons =['He','She','I','They']\n",
    "objects=['letter','water','tree','wood']\n",
    "activity=['play']\n",
    "watching=['play','movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amber',\n",
       " 'ash',\n",
       " 'asphalt',\n",
       " 'auburn',\n",
       " 'avocado',\n",
       " 'aquamarine',\n",
       " 'azure',\n",
       " 'beige',\n",
       " 'bisque',\n",
       " 'black',\n",
       " 'blue',\n",
       " 'bone',\n",
       " 'bordeaux',\n",
       " 'brass',\n",
       " 'bronze',\n",
       " 'brown',\n",
       " 'burgundy',\n",
       " 'camel',\n",
       " 'caramel',\n",
       " 'canary',\n",
       " 'celeste',\n",
       " 'cerulean',\n",
       " 'champagne',\n",
       " 'charcoal',\n",
       " 'chartreuse',\n",
       " 'chestnut',\n",
       " 'chocolate',\n",
       " 'citron',\n",
       " 'claret',\n",
       " 'coal',\n",
       " 'cobalt',\n",
       " 'coffee',\n",
       " 'coral',\n",
       " 'corn',\n",
       " 'cream',\n",
       " 'crimson',\n",
       " 'cyan',\n",
       " 'denim',\n",
       " 'desert',\n",
       " 'ebony',\n",
       " 'ecru',\n",
       " 'emerald',\n",
       " 'feldspar',\n",
       " 'fuchsia',\n",
       " 'gold',\n",
       " 'gray',\n",
       " 'green',\n",
       " 'heather',\n",
       " 'indigo',\n",
       " 'ivory',\n",
       " 'jet',\n",
       " 'khaki',\n",
       " 'lime',\n",
       " 'magenta',\n",
       " 'maroon',\n",
       " 'mint',\n",
       " 'navy',\n",
       " 'olive',\n",
       " 'orange',\n",
       " 'pink',\n",
       " 'plum',\n",
       " 'purple',\n",
       " 'red',\n",
       " 'rust',\n",
       " 'salmon',\n",
       " 'sienna',\n",
       " 'silver',\n",
       " 'snow',\n",
       " 'steel',\n",
       " 'tan',\n",
       " 'teal',\n",
       " 'tomato',\n",
       " 'violet',\n",
       " 'white',\n",
       " 'yellow']"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc = \"A tree is made of wood.\"\n",
    "qs = \"What is made of wood?\"\n",
    "stc=stc[:len(stc)-1]\n",
    "qs=qs[:len(qs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_list = stc.split(\" \")\n",
    "qs_list = qs.split(\" \")\n",
    "#removing the special characters from the string\n",
    "qs_list_cleaned=[]\n",
    "stc_list_cleaned=[]\n",
    "for i in range(0,len(qs_list)):\n",
    "    temp=\"\"\n",
    "    for character in qs_list[i]:\n",
    "        if not(character==\"?\") or not(character==\".\") :\n",
    "            temp+=character\n",
    "            \n",
    "    qs_list_cleaned.append(temp)\n",
    "    \n",
    "for i in range(0,len(stc_list)):\n",
    "    temp=\"\"\n",
    "    for character in stc_list[i]:\n",
    "        if not(character==\"?\") or not(character==\".\"):\n",
    "            temp+=character\n",
    "            \n",
    "    stc_list_cleaned.append(temp)\n",
    "\n",
    "#POS tagging of question and sentence\n",
    "stc_list2=[]\n",
    "qs_list2=[]\n",
    "for i in range(0,len(stc_list_cleaned)):\n",
    "    for j in range(0,len(content_list2)):\n",
    "        if stc_list_cleaned[i].lower() == content_list2[j][0].lower():\n",
    "            stc_list2.append([stc_list_cleaned[i],content_list2[j][1]])\n",
    "    if (\":\" in stc_list_cleaned[i]):\n",
    "            stc_list2.append([stc_list_cleaned[i],'TIME'])\n",
    "            \n",
    "for i in range(0,len(qs_list_cleaned)):\n",
    "    for j in range(0,len(content_list2)):\n",
    "        if qs_list_cleaned[i].lower() == content_list2[j][0].lower():\n",
    "            qs_list2.append([qs_list_cleaned[i],content_list2[j][1]])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'DET'], ['tree', 'NOUN'], ['is', 'AUX'], ['made', 'VERB'], ['of', 'ADP'], ['wood', 'NOUN']]\n",
      "[['What', 'PRON'], ['is', 'AUX'], ['made', 'VERB'], ['of', 'ADP'], ['wood', 'NOUN']]\n"
     ]
    }
   ],
   "source": [
    "print(stc_list2)\n",
    "print(qs_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stc_list2[i][1] == 'PROPN') or ([k for k in stc_list2[i] if k[0] in persons]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in stc_list2 if k[i][0] in persons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['She', 'PRON'],\n",
       " ['will', 'AUX'],\n",
       " ['write', 'VERB'],\n",
       " ['him', 'PRON'],\n",
       " ['a', 'DET'],\n",
       " ['love', 'NOUN'],\n",
       " ['letter', 'NOUN']]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She']"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in stc_list2[i] if k in persons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('Who' in qs_list_cleaned) and not('to' in qs_list_cleaned) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if (stc_list2[i][1] == 'PROPN') or ([k for k in stc_list2[i] if k in persons]) :\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if ('What' in qs_list_cleaned) and not('watch' in qs_list_cleaned) and [k for k in stc_list2 if k in qs_list2] and flag == 0:\n",
    "    comn = [k for k in stc_list2 if k in qs_list2][0][0]\n",
    "    ans = [i for i in [item[0] for item in [k for k in stc_list2 if k[0] in objects]] if (i in objects) and not(i ==comn)]\n",
    "    flag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('What' in qs_list_cleaned) and not('watch' in qs_list_cleaned) and [k for k in stc_list2 if k in qs_list2] and flag == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'made', 'of', 'wood']"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[0] for item in [k for k in stc_list2 if k[0] in qs_list_cleaned]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'AUX']"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'PRON'],\n",
       " ['is', 'AUX'],\n",
       " ['made', 'VERB'],\n",
       " ['of', 'ADP'],\n",
       " ['wood', 'NOUN']]"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "stc_list = stc.split(\" \")\n",
    "qs_list = qs.split(\" \")\n",
    "#removing the special characters from the string\n",
    "qs_list_cleaned=[]\n",
    "stc_list_cleaned=[]\n",
    "for i in range(0,len(qs_list)):\n",
    "    temp=\"\"\n",
    "    for character in qs_list[i]:\n",
    "        if not(character==\"?\") or not(character==\".\") :\n",
    "            temp+=character\n",
    "            \n",
    "    qs_list_cleaned.append(temp)\n",
    "    \n",
    "for i in range(0,len(stc_list)):\n",
    "    temp=\"\"\n",
    "    for character in stc_list[i]:\n",
    "        if not(character==\"?\") or not(character==\".\"):\n",
    "            temp+=character\n",
    "            \n",
    "    stc_list_cleaned.append(temp)\n",
    "\n",
    "#POS tagging of question and sentence\n",
    "stc_list2=[]\n",
    "qs_list2=[]\n",
    "for i in range(0,len(stc_list_cleaned)):\n",
    "    for j in range(0,len(content_list2)):\n",
    "        if stc_list_cleaned[i].lower() == content_list2[j][0].lower():\n",
    "            stc_list2.append([stc_list_cleaned[i],content_list2[j][1]])\n",
    "    if (\":\" in stc_list_cleaned[i]):\n",
    "            stc_list2.append([stc_list_cleaned[i],'TIME'])\n",
    "            \n",
    "for i in range(0,len(qs_list_cleaned)):\n",
    "    for j in range(0,len(content_list2)):\n",
    "        if qs_list_cleaned[i].lower() == content_list2[j][0].lower():\n",
    "            qs_list2.append([qs_list_cleaned[i],content_list2[j][1]])\n",
    "            \n",
    "qs_list_pos=[]\n",
    "qs_list_pos = [item[1] for item in  qs_list2]\n",
    "\n",
    "stc_list_pos=[]\n",
    "stc_list_pos = [item[1] for item in  stc_list2]\n",
    "\n",
    "#Common question            \n",
    "cmn_qs_prns = ['Who','What','Which','Where','When','How']\n",
    "cmn_qs_prns2 =[]\n",
    "for i in range(0,len(cmn_qs_prns)):\n",
    "    for j in range(0,len(content_list2)):\n",
    "        if cmn_qs_prns[i].lower() == content_list2[j][0].lower():\n",
    "            cmn_qs_prns2.append([cmn_qs_prns[i],content_list2[j][1]])\n",
    "\n",
    "\n",
    "ans = \"\"\n",
    "comn=\"\"\n",
    "flag=0\n",
    "if ('Who' in qs_list_cleaned) and ('to' in qs_list_cleaned) and ('with' in qs_list_cleaned) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'PROPN' and not(stc_list2[i][0] in qs_list_cleaned):\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "if ('Who' in qs_list_cleaned) and not('to' in qs_list_cleaned) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if (stc_list2[i][1] == 'PROPN') or ([k for k in stc_list2[i] if k in persons]) :\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "if ('Who' in qs_list_cleaned) and ('to' in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='PROPN'] :\n",
    "    comn=[k for k in stc_list2 if k in qs_list2 and k[1]=='PROPN'][0]\n",
    "        \n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2[i][1] == 'PROPN' and not(stc_list2[i][0] == comn[0]) :\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "            \n",
    "if ('Who' in qs_list_cleaned) and ('is' in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN']:\n",
    "    comn=[k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2[i][1] == 'PROPN' or stc_list2[i][1] == 'NOUN' and not(stc_list2[i][0] == comn[0]) :\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break  \n",
    "            \n",
    "if ('Who' in qs_list_cleaned) and ('told' in qs_list_cleaned) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):       \n",
    "        if stc_list2[i][1] == 'PRON' or stc_list2[i][1] == 'NOUN':\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break  \n",
    "\n",
    "if ('When' in qs_list_cleaned) and flag==0:\n",
    "    #common verb between question and sentence\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][0] in time_day:\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "if ('Where' in qs_list_cleaned) and flag==0:\n",
    "    #common verb between question and sentence\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][0] in places:\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "if ('Where' in qs_list_cleaned) and [k for k in stc_list2 if k in qs_list2 and k[1]=='VERB'] and flag==0 and ('VERB' in qs_list_pos) and  ('VERB' in stc_list_pos):\n",
    "    #common verb between question and sentence\n",
    "    comn=[k for k in stc_list2 if k in qs_list2 and k[1]=='VERB'][0]\n",
    "     \n",
    "    for i in range(0,len(stc_list2)):\n",
    "         if comn: \n",
    "            if stc_list2.index(comn) < stc_list2.index(stc_list2[i]) and stc_list2[i][1] == 'NOUN':\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "\n",
    "if ('How' in qs_list_cleaned) and  ('ADJ' in qs_list_pos) and ('PROPN' in qs_list_pos) and flag==0 :\n",
    "    comn=[k for k in stc_list2 if k in qs_list2][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2[i][1]=='ADJ' and not(stc_list2[i][0]==comn[0]) :\n",
    "                ans=stc_list2[i][0]\n",
    "                flag=1 \n",
    "                break\n",
    "        elif stc_list2[i][1]=='ADJ':\n",
    "            ans=stc_list2[i][0]\n",
    "            flag=1 \n",
    "            break\n",
    "            \n",
    "                \n",
    "                \n",
    "if ('How' in qs_list_cleaned) and  ('many' in qs_list_cleaned) and ([i for i in stc_list_cleaned if i in numbers]) and flag==0 :\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1]=='NUM':\n",
    "            ans=stc_list2[i][0] + ' '+ [i for i in stc_list_cleaned if i in numbers][0]\n",
    "            flag=1 \n",
    "            break\n",
    "\n",
    "\n",
    "if ('How' in qs_list_cleaned) and qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='How'][0])+1][1] == 'ADJ' and not('far' in qs_list_cleaned) and not('distant' in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'] :\n",
    "    #common noun between question and sentence\n",
    "    comn=[k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2.index(comn) > stc_list2.index(stc_list2[i]) and stc_list2[i][1] == 'ADJ':\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "\n",
    "if ('How' in qs_list_cleaned) and qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='How'][0])+1][1] == 'ADJ' and ('far' in qs_list_cleaned) or ('distant' in qs_list_cleaned) and flag==0:\n",
    "    #common noun between question and sentence\n",
    "    ans = stc_list2[stc_list2.index([i for i in stc_list2 if i[0] in distance_measures][0])-1][0]+' '+ [i for i in stc_list2 if i[0] in distance_measures][0][0]\n",
    "    flag=1\n",
    "    \n",
    "if ('How' in qs_list_cleaned) and qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='How'][0])+1][1] == 'VERB' and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN']:\n",
    "    #common noun between question and sentence\n",
    "    comn=[k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2.index(comn) > stc_list2.index(stc_list2[i]) and stc_list2[i][1] == 'NOUN':\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "\n",
    "if ('What' in qs_list_cleaned) and not('watch' in qs_list_cleaned) and [k for k in stc_list2 if k in qs_list2] and flag == 0:\n",
    "    comn = [k for k in stc_list2 if k in qs_list2][0][0]\n",
    "    ans = [i for i in [item[0] for item in [k for k in stc_list2 if k[0] in objects]] if (i in objects) and not(i ==comn)]\n",
    "    flag = 1\n",
    "\n",
    "if ('What' in qs_list_cleaned) and not('VERB' in qs_list_pos) and not('NOUN' in qs_list_pos) and ('ADJ' in qs_list_pos) and flag==0:\n",
    "    if [i for i in stc_list_cleaned if i in objects]:\n",
    "        ans=[i for i in stc_list_cleaned if i in objects][0]\n",
    "        flag=1\n",
    "    else:\n",
    "        for i in range(0,len(stc_list2)):\n",
    "            if stc_list2[i][1] == 'NOUN':\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break               \n",
    "\n",
    "if ('What' in qs_list_cleaned) and ('watch' in qs_list_cleaned) and  flag==0:\n",
    "    ans=[i for i in stc_list_cleaned if i in watching][0]\n",
    "    flag=1                \n",
    "                \n",
    "if ('What' in qs_list_cleaned) and len([i for i in qs_list_cleaned if i=='do'])>1 and [i for i in stc_list_cleaned if i in activity] and flag==0:\n",
    "    ans=[i for i in stc_list_cleaned if i in activity][0]\n",
    "    flag=1\n",
    "                \n",
    "if ('What' in qs_list_cleaned) and ([i for i in stc_list_cleaned if i in objects]) and ('VERB' in qs_list_pos) and flag==0: \n",
    "    ans=[i for i in stc_list_cleaned if i in objects][0]\n",
    "    flag=1\n",
    "    \n",
    "\n",
    "if ('What' in qs_list_cleaned) or ('what' in qs_list_cleaned) and ('time' in qs_list_cleaned)  and flag==0: \n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'TIME':\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "if ('What' in qs_list_cleaned) and  ('color' in qs_list_cleaned) and len([i for i in stc_list_cleaned if (i in colors_list)])>1  and flag==0 and ('NOUN' in qs_list_pos) and  ('NOUN' in stc_list_pos): \n",
    "    ans = stc_list2[stc_list2.index([k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0])-1][0] \n",
    "    flag=1\n",
    "\n",
    "if ('color' in qs_list_cleaned) and ('What' in qs_list_cleaned) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][0] in colors_list:\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "\n",
    "if ('What' in qs_list_cleaned) and (\"VERB\" in qs_list_pos) and not(\"sing\" in qs_list_cleaned) and flag==0: \n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'VERB':\n",
    "            for j in range(i,len(stc_list2)):\n",
    "                if stc_list2[j][1] == 'NOUN':\n",
    "                    ans = stc_list2[j][0]\n",
    "                    flag=1\n",
    "                    break\n",
    " \n",
    "if ('What' in qs_list_cleaned) and not(\"VERB\" in qs_list_pos) and not(\"sing\" in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k[0].lower() in [item[0] for item in  qs_list2] and k[1]=='NOUN']: \n",
    "    comm=[k for k in stc_list2 if k[0].lower() in [item[0] for item in  qs_list2] and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'NOUN' and not(stc_list2[i][0].lower()==comm[0].lower()):\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break                   \n",
    "            \n",
    "if ('What' in qs_list_cleaned) and (qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='What'][0])+1][1]=='AUX') and (\"NOUN\" in qs_list_pos) and (\"VERB\" in qs_list_pos)  and not(\"sing\" in qs_list_cleaned) and flag==0: \n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'ADJ':\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    " \n",
    "if ('What' in qs_list_cleaned) and (qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='What'][0])+1][1]=='AUX') and (\"NOUN\" in qs_list_pos) and (\"VERB\" in qs_list_pos)  and (\"sing\" in qs_list_cleaned) and flag==0: \n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'NOUN':\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break           \n",
    "            \n",
    "if ('What' in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'] :\n",
    "    comn =[k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2[i][1] == 'NOUN' and not(stc_list2[i][0]==comn[0]):\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "            \n",
    "if ('What' in qs_list_cleaned) and flag==0 and [k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'] :\n",
    "    comn =[k for k in stc_list2 if k in qs_list2 and k[1]=='NOUN'][0]\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if comn:\n",
    "            if stc_list2[i][1] == 'NOUN' and not(stc_list2[i][0]==comn[0]):\n",
    "                ans = stc_list2[i][0]\n",
    "                flag=1\n",
    "                break\n",
    "\n",
    "if ('ADV' in qs_list_pos) and ('ADJ' in qs_list_pos ) and flag==0:\n",
    "    for i in range(0,len(stc_list2)):\n",
    "        if stc_list2[i][1] == 'ADJ':\n",
    "            ans = stc_list2[i][0]\n",
    "            flag=1\n",
    "            break\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('What' in qs_list_cleaned) and (qs_list2[qs_list2.index([i for i in qs_list2 if i[0]=='What'][0])+1][1]=='AUX') and (\"NOUN\" in qs_list_pos) and (\"VERB\" in qs_list_pos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('color' in qs_list_cleaned) and ('What' in qs_list_cleaned) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADV', 'ADJ', 'NOUN', 'AUX', 'NOUN', 'DET', 'NOUN']"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-643-865ccbc8a0e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstc_list2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqs_list2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'PROPN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if ('NOUN' in qs_list_pos) and  ('NOUN' in stc_list_pos)\n",
    "    [k for k in stc_list2 if k in qs_list2 and k[1]=='PROPN'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Watch', 'NOUN'], ['your', 'PRON'], ['step', 'NOUN']]"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'PRON'], ['should', 'AUX'], ['you', 'PRON'], ['watch', 'NOUN']]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm=[k for k in stc_list2 if k[0].lower() in [item[0] for item in  qs_list2] and k[1]=='NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc_list2[0][0].lower()==comm[0][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'AUX', 'PRON', 'NOUN']"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[1] for item in  qs_list2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
